#!/usr/bin/env python3
"""
AI PM Resume Analyzer
Analyzes resumes against the 6-pillar AI PM framework using AI
"""

import sys
import os
import argparse
import json
from pathlib import Path
from datetime import datetime
import re

# Add parent directory to path for imports
sys.path.insert(0, str(Path(__file__).parent.parent))

try:
    from dotenv import load_dotenv
    import PyPDF2
except ImportError:
    print("ERROR: Required packages not installed.")
    print("Please run: pip install -r requirements.txt")
    sys.exit(1)

# Import API clients (will be imported dynamically based on availability)
OPENAI_AVAILABLE = False
ANTHROPIC_AVAILABLE = False
GOOGLE_AVAILABLE = False

try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    pass

try:
    import anthropic
    ANTHROPIC_AVAILABLE = True
except ImportError:
    pass

try:
    import google.generativeai as genai
    GOOGLE_AVAILABLE = True
except ImportError:
    pass


class ResumeAnalyzer:
    """Analyze resumes using AI against the 6-pillar framework"""

    FRAMEWORK_PILLARS = {
        "pillar_1": {
            "name": "Technical Skills & Hands-On Building",
            "weight": 20,
            "description": "Engineering background, coding ability, hands-on AI building, personal projects",
            "what_exceptional_looks_like": [
                "Multiple personal AI projects spanning different domains (productivity, creative, workflow automation)",
                "Public GitHub repos showing real experimentation, not just tutorials",
                "Evidence of building tools to solve their own problems",
                "Portfolio approach: 8-10 concurrent side projects demonstrating creative range",
                "Projects built in hours/days, not weeks/months (speed is critical in 2025)",
                "Unusual creativity in applications showing original thinking"
            ],
            "what_NOT_sufficient": [
                "Only managed teams building AI features without personal hands-on work",
                "Just used ChatGPT as productivity tool",
                "Took online courses but didn't build anything",
                "Pure management role with no IC technical work"
            ],
            "strong_signals": [
                "GitHub repos with AI experiments and real projects",
                "Building in 1-2 hour timeframes (not days)",
                "Tools solving personal problems or for family/kids",
                "Diverse experimentation across multiple domains",
                "Evidence of using AI creatively in unexpected ways"
            ]
        },
        "pillar_2": {
            "name": "Product Thinking & 0-to-1 Leadership",
            "weight": 25,
            "description": "User empathy, problem definition, navigating ambiguity, 0-to-1 experience, decision-making under uncertainty",
            "what_exceptional_looks_like": [
                "Multiple 0-to-1 product launches (not just feature additions to mature products)",
                "Clear evidence of leading through ambiguity and making decisions without complete information",
                "User-centered approach with empathy for pain points",
                "Examples of pivots handled gracefully with team trust maintained",
                "Product metrics and outcomes clearly tied to user value"
            ],
            "what_NOT_sufficient": [
                "Only worked on mature products with clear requirements",
                "Feature-focused rather than systems-focused thinking",
                "No evidence of handling ambiguity or making hard tradeoffs"
            ],
            "strong_signals": [
                "Language about 'led team through' ambiguity",
                "0-to-1 launches with measurable user impact",
                "Evidence of building user trust during uncertainty",
                "Clear problem framing and hypothesis-driven approach"
            ]
        },
        "pillar_3": {
            "name": "Deep AI Intuition & Applied Creativity (NON-NEGOTIABLE)",
            "weight": 20,
            "description": "Hands-on AI experience, understanding of capabilities/limitations, creative applications, staying current",
            "what_exceptional_looks_like": [
                "Personal AI projects showing deep intuition about what's possible",
                "Creative applications of AI in unexpected ways",
                "Evidence of experimenting with models, fine-tuning, or novel use cases",
                "Understanding of AI limitations through hands-on building",
                "Staying current with latest models and techniques",
                "Can generate creative ideas consistently (not just one idea)"
            ],
            "what_NOT_sufficient": [
                "Only managed ML engineers without hands-on AI work",
                "Worked with ML teams but never built with AI personally",
                "Defined requirements for AI systems without understanding them deeply",
                "Generic PM experience with 'AI' label added"
            ],
            "strong_signals": [
                "Personal AI agents or automation built",
                "Creative use cases showing original thinking",
                "Blog posts about AI learnings and experiments",
                "Evidence of using AI daily to be more productive",
                "Systems thinking: 'Built workflow using agents X and Y'"
            ]
        },
        "pillar_4": {
            "name": "Communication & Compelling Storytelling",
            "weight": 10,
            "description": "Written/verbal communication, stakeholder management, inspiring narratives, building in public",
            "what_exceptional_looks_like": [
                "Resume itself tells compelling story about their journey",
                "Building in public: blog posts, LinkedIn, speaking, GitHub",
                "Ability to inspire teams to build things that don't exist yet",
                "Clear articulation of vision and 'why' behind products",
                "Evidence of thought leadership and sharing learnings publicly"
            ],
            "what_NOT_sufficient": [
                "Only internal communication, no public presence",
                "Generic corporate communication without compelling narratives",
                "No evidence of inspiring others or building belief"
            ],
            "strong_signals": [
                "Active blog, Substack, or LinkedIn with AI insights",
                "Speaking at events or meetups",
                "Public GitHub repos (building in public)",
                "Resume narrative that makes their journey clear and compelling"
            ]
        },
        "pillar_5": {
            "name": "Strategic Thinking & Second-Order Vision",
            "weight": 15,
            "description": "Systems thinking, platforms vs features, future-proofing, market positioning, paradigm shifts",
            "what_exceptional_looks_like": [
                "Second-order thinking: building platforms/tools that enable others to build",
                "Understanding paradigm shifts (not just incremental improvements)",
                "Designing for future AI capabilities, not just current limitations",
                "Projects that get better as AI improves (future-proof architecture)",
                "Vision for where AI is going, not just where it is"
            ],
            "what_NOT_sufficient": [
                "Only first-order thinking: building specific features",
                "Incremental improvements to existing workflows",
                "No evidence of systems thinking or platform approach"
            ],
            "strong_signals": [
                "Language about 'platforms,' 'frameworks,' 'enabling infrastructure'",
                "Examples of enabling others to build (not just building features)",
                "Understanding that incremental improvements get disrupted",
                "Projects architected to leverage future AI advances"
            ]
        },
        "pillar_6": {
            "name": "Full-Spectrum Execution & Rapid Shipping",
            "weight": 10,
            "description": "Bias for action, shipping products, rapid prototyping, overcoming obstacles, velocity",
            "what_exceptional_looks_like": [
                "Evidence of rapid prototyping: built in hours (1-2 hours), not days/weeks",
                "Multiple shipped products with user adoption",
                "Language of ownership: 'I built' not 'we discussed'",
                "Going from idea to working prototype same-day",
                "Treating ideas as commoditizable, maintaining high velocity"
            ],
            "what_NOT_sufficient": [
                "Only 'managed' or 'led' projects without shipping",
                "Slow execution measured in weeks/months",
                "Just planning and strategy without hands-on building"
            ],
            "strong_signals": [
                "Timeframes of hours/days in project descriptions",
                "Portfolio of shipped products (not just managed)",
                "Evidence of rapid iteration and de-risking through speed",
                "Multiple concurrent projects showing high velocity"
            ]
        }
    }

    # The Three Critical Questions (Apply to Every Project)
    CRITICAL_QUESTIONS = {
        "paradigm_shift": {
            "question": "Are you building a faster horse or a car? Process improvement or entirely new workflow?",
            "incremental_example": "Built AI chatbot to answer support questions 20% faster",
            "transformational_example": "Created AI self-service platform that eliminated 60% of support tickets by teaching users through interactive workflows"
        },
        "future_proofing": {
            "question": "When next AI model drops, will it commoditize your feature or unlock new capabilities?",
            "vulnerable_example": "Built summarization tool using GPT-4",
            "future_proof_example": "Built workflow orchestration where summarization is one interchangeable step; gets better as models improve"
        },
        "magic_wand": {
            "question": "What human-in-the-loop step exists only because of technical limitations?",
            "present_bound_example": "Added human review because AI makes mistakes",
            "future_oriented_example": "Designed pluggable verification layer; uses humans now, but architected for future AI verification without redesign"
        }
    }

    # Minimum Thresholds (Must Have to Be Considered)
    MINIMUM_THRESHOLDS = {
        "personal_ai_projects": {
            "minimum_required": 1,
            "strong_signal": "2-5 projects showing diverse experimentation",
            "exceptional_signal": "Active portfolio of 8-10 concurrent side projects",
            "rationale": "One project = basic hands-on ability. Multiple = creative range. Large portfolio = continuous idea generation"
        },
        "building_in_public": {
            "required": True,
            "examples": ["LinkedIn posts", "Blog/Substack", "GitHub repos", "Speaking at events", "Sharing on social platforms"],
            "rationale": "Demonstrates thought leadership and ability to articulate vision"
        },
        "resume_creativity": {
            "required": True,
            "red_flag": "Plain text wall resume",
            "rationale": "Resume design itself demonstrates PM creativity competency. Boring resume signals lack of creativity essential for AI PM work"
        }
    }

    # Must-Have Signals (All Required for Strong Screen)
    MUST_HAVE_SIGNALS = [
        "At least 1 personal AI project with evidence",
        "Experience shipping products (not just planning)",
        "Clear alignment with AI/ML product space",
        "Evidence of continuous learning and staying current with AI",
        "Compelling narrative explaining their journey"
    ]

    # Strong Differentiation Signals (Need 3+ for Strong Screen)
    DIFFERENTIATION_SIGNALS = [
        "Multiple 0-to-1 product launches",
        "Technical depth (can discuss AI architectures, not just manage)",
        "Portfolio of side projects showing creativity (ideally 8-10 concurrent)",
        "Thought leadership (blog, speaking, community contributions)",
        "Exceptional design taste evident in resume/portfolio",
        "Speed of execution (examples of building in hours not months)",
        "Systems thinking (built platforms/tools, not just features)",
        "Building in public with visible presence"
    ]

    # Red Flags (Strong Pass Signals)
    RED_FLAGS = [
        "No evidence of hands-on AI work or personal projects",
        "Pure management role with no IC product work",
        "Only 'managed' or 'led' teams - no 'I built' or 'I shipped'",
        "Buzzword-heavy with no substance or specific examples",
        "Plain text wall resume showing no creativity",
        "No shipped products, only planned or discussed",
        "Unclear why they want to work in AI",
        "Slow execution timeframes (weeks/months instead of hours/days)"
    ]

    # Yellow Flags (Investigate Further)
    YELLOW_FLAGS = [
        "Only corporate/assigned work, no personal projects",
        "Gaps in timeline without explanation",
        "Generic PM language with no AI-specific depth",
        "No links or verifiable work products",
        "No public presence or building in public",
        "Only worked on mature products, no 0-to-1 experience",
        "First-order thinking only (features, not platforms)"
    ]

    # Available models for each provider
    AVAILABLE_MODELS = {
        "openai": {
            "gpt-5": {"name": "GPT-5", "description": "Most advanced reasoning model", "cost": "$$$"},
            "gpt-5-mini": {"name": "GPT-5 Mini", "description": "Faster, cost-effective GPT-5", "cost": "$$"},
            "gpt-4o": {"name": "GPT-4o", "description": "Budget-friendly option", "cost": "$"}
        },
        "anthropic": {
            "claude-sonnet-4-5-20250929": {"name": "Claude Sonnet 4.5", "description": "Best for coding and complex analysis", "cost": "$$$"},
            "claude-haiku-4-5": {"name": "Claude Haiku 4.5", "description": "Fast and cost-effective", "cost": "$"},
            "claude-opus-4-1": {"name": "Claude Opus 4.1", "description": "Most capable reasoning model", "cost": "$$$$"}
        },
        "google": {
            "gemini-2.5-pro": {"name": "Gemini 2.5 Pro", "description": "Advanced thinking model", "cost": "$$$"},
            "gemini-2.5-flash": {"name": "Gemini 2.5 Flash", "description": "Fast and intelligent", "cost": "$"}
        }
    }

    # Default models for each provider
    DEFAULT_MODELS = {
        "openai": "gpt-5",
        "anthropic": "claude-sonnet-4-5-20250929",
        "google": "gemini-2.5-pro"
    }

    def __init__(self, api_provider="openai", api_key=None, model=None):
        self.api_provider = api_provider.lower()
        self.api_key = api_key
        self.model = model
        self._initialize_client()

    def _initialize_client(self):
        """Initialize the AI client based on provider"""
        if self.api_provider == "openai":
            if not OPENAI_AVAILABLE:
                raise ImportError("OpenAI package not installed. Run: pip install openai")
            if not self.api_key:
                raise ValueError("OpenAI API key required")

            # Set default model if not specified
            if not self.model:
                self.model = self.DEFAULT_MODELS["openai"]

            # Validate model
            if self.model not in self.AVAILABLE_MODELS["openai"]:
                raise ValueError(f"Unknown OpenAI model: {self.model}. Available: {', '.join(self.AVAILABLE_MODELS['openai'].keys())}")

            self.client = openai.OpenAI(api_key=self.api_key)

        elif self.api_provider == "anthropic":
            if not ANTHROPIC_AVAILABLE:
                raise ImportError("Anthropic package not installed. Run: pip install anthropic")
            if not self.api_key:
                raise ValueError("Anthropic API key required")

            # Set default model if not specified
            if not self.model:
                self.model = self.DEFAULT_MODELS["anthropic"]

            # Validate model
            if self.model not in self.AVAILABLE_MODELS["anthropic"]:
                raise ValueError(f"Unknown Anthropic model: {self.model}. Available: {', '.join(self.AVAILABLE_MODELS['anthropic'].keys())}")

            self.client = anthropic.Anthropic(api_key=self.api_key)

        elif self.api_provider == "google":
            if not GOOGLE_AVAILABLE:
                raise ImportError("Google Generative AI package not installed. Run: pip install google-generativeai")
            if not self.api_key:
                raise ValueError("Google API key required")

            # Set default model if not specified
            if not self.model:
                self.model = self.DEFAULT_MODELS["google"]

            # Validate model
            if self.model not in self.AVAILABLE_MODELS["google"]:
                raise ValueError(f"Unknown Google model: {self.model}. Available: {', '.join(self.AVAILABLE_MODELS['google'].keys())}")

            genai.configure(api_key=self.api_key)
            self.client = genai.GenerativeModel(self.model)

        else:
            raise ValueError(f"Unknown API provider: {self.api_provider}")

    def extract_text_from_document(self, file_path):
        """Extract text content from resume (.pdf, .doc, .docx)"""
        import subprocess

        file_ext = Path(file_path).suffix.lower()

        try:
            if file_ext in ['.doc', '.docx']:
                # Use pandoc for Word documents
                result = subprocess.run([
                    'pandoc', file_path,
                    '-t', 'plain',
                    '--wrap=none'
                ], capture_output=True, text=True, check=True)
                return result.stdout.strip()

            elif file_ext == '.pdf':
                # Use PyPDF2 for PDF files
                with open(file_path, 'rb') as file:
                    reader = PyPDF2.PdfReader(file)
                    text = ""
                    for page in reader.pages:
                        text += page.extract_text() + "\n"
                    return text.strip()

            else:
                raise ValueError(f"Unsupported file format: {file_ext}. Supported formats: .pdf, .doc, .docx")

        except subprocess.CalledProcessError as e:
            raise Exception(f"Error extracting text from {file_ext}: {e.stderr}")
        except Exception as e:
            raise Exception(f"Error reading document: {str(e)}")

    def convert_pdf_to_images(self, file_path):
        """Convert PDF pages to images for visual analysis"""
        try:
            from pdf2image import convert_from_path
            # Convert only first page for resume design evaluation
            images = convert_from_path(file_path, first_page=1, last_page=1, dpi=200)
            return images[0] if images else None
        except ImportError:
            # pdf2image not available, return None (text-only analysis)
            return None
        except Exception as e:
            print(f"‚ö†Ô∏è  Warning: Could not convert PDF to image: {str(e)}")
            return None

    def create_analysis_prompt(self, resume_text):
        """Create the prompt for AI analysis with comprehensive framework"""
        prompt = f"""You are an expert AI Product Manager hiring consultant specializing in evaluating candidates for 2025 AI PM roles.

# CONTEXT: What We're Looking For in 2025

The AI PM role has fundamentally changed. We need people who:
- **BUILD in hours, not days/weeks** - Speed is critical; ideas are commoditizable
- **Maintain a PORTFOLIO of 8-10 concurrent side projects** - Not one idea, but continuous idea generation
- **Build in PUBLIC** - Blog, LinkedIn, GitHub, speaking - demonstrating thought leadership
- **Think SECOND-ORDER** - Platforms/tools that enable others to build, not just features
- **Have DEEP AI intuition** - From hands-on building, not just managing ML teams

# RESUME TO EVALUATE

{resume_text}

# EVALUATION METHODOLOGY

## STEP 1: Minimum Thresholds (Screen Out Immediately if Missing)

Check for these MINIMUM requirements:

**Personal AI Projects Threshold:**
{json.dumps(self.MINIMUM_THRESHOLDS['personal_ai_projects'], indent=2)}

**Building in Public Threshold:**
{json.dumps(self.MINIMUM_THRESHOLDS['building_in_public'], indent=2)}

**Resume Creativity Threshold:**
{json.dumps(self.MINIMUM_THRESHOLDS['resume_creativity'], indent=2)}

If candidate fails ANY minimum threshold ‚Üí Decision = "No Screen" (stop evaluation)

## STEP 2: Red Flags Check (Strong Pass Signals)

Check for these RED FLAGS (any one is serious concern):
{json.dumps(self.RED_FLAGS, indent=2)}

## STEP 3: Yellow Flags (Investigate Further)

Note any YELLOW FLAGS (multiple yellows = concern):
{json.dumps(self.YELLOW_FLAGS, indent=2)}

## STEP 4: The Three Critical Questions (Apply to EVERY Project Listed)

For each significant project/role on the resume, ask:

**Question 1: Paradigm Shift?**
{json.dumps(self.CRITICAL_QUESTIONS['paradigm_shift'], indent=2)}

**Question 2: Future-Proofing?**
{json.dumps(self.CRITICAL_QUESTIONS['future_proofing'], indent=2)}

**Question 3: Magic Wand Test?**
{json.dumps(self.CRITICAL_QUESTIONS['magic_wand'], indent=2)}

## STEP 5: Six Pillars Deep Evaluation

Evaluate each pillar with detailed criteria:

### Pillar 1: {self.FRAMEWORK_PILLARS['pillar_1']['name']} (Weight: {self.FRAMEWORK_PILLARS['pillar_1']['weight']}%)

**Description:** {self.FRAMEWORK_PILLARS['pillar_1']['description']}

**What Exceptional Looks Like:**
{json.dumps(self.FRAMEWORK_PILLARS['pillar_1']['what_exceptional_looks_like'], indent=2)}

**What is NOT Sufficient:**
{json.dumps(self.FRAMEWORK_PILLARS['pillar_1']['what_NOT_sufficient'], indent=2)}

**Strong Signals to Look For:**
{json.dumps(self.FRAMEWORK_PILLARS['pillar_1']['strong_signals'], indent=2)}

Score: 0-10 where:
- 0-3: Does not meet minimum bar
- 4-5: Functional but not strong
- 6-7: Solid, meets expectations
- 8-9: Strong, above average
- 10: Exceptional, top-tier

### Pillar 2: {self.FRAMEWORK_PILLARS['pillar_2']['name']} (Weight: {self.FRAMEWORK_PILLARS['pillar_2']['weight']}%)

**Description:** {self.FRAMEWORK_PILLARS['pillar_2']['description']}

**What Exceptional Looks Like:**
{json.dumps(self.FRAMEWORK_PILLARS['pillar_2']['what_exceptional_looks_like'], indent=2)}

**What is NOT Sufficient:**
{json.dumps(self.FRAMEWORK_PILLARS['pillar_2']['what_NOT_sufficient'], indent=2)}

**Strong Signals to Look For:**
{json.dumps(self.FRAMEWORK_PILLARS['pillar_2']['strong_signals'], indent=2)}

Score: 0-10 (same scale as above)

### Pillar 3: {self.FRAMEWORK_PILLARS['pillar_3']['name']} (Weight: {self.FRAMEWORK_PILLARS['pillar_3']['weight']}%) - NON-NEGOTIABLE

**Description:** {self.FRAMEWORK_PILLARS['pillar_3']['description']}

**What Exceptional Looks Like:**
{json.dumps(self.FRAMEWORK_PILLARS['pillar_3']['what_exceptional_looks_like'], indent=2)}

**What is NOT Sufficient:**
{json.dumps(self.FRAMEWORK_PILLARS['pillar_3']['what_NOT_sufficient'], indent=2)}

**Strong Signals to Look For:**
{json.dumps(self.FRAMEWORK_PILLARS['pillar_3']['strong_signals'], indent=2)}

Score: 0-10 (same scale) - **CRITICAL: Score < 6 = automatic "No Screen"**

### Pillar 4: {self.FRAMEWORK_PILLARS['pillar_4']['name']} (Weight: {self.FRAMEWORK_PILLARS['pillar_4']['weight']}%)

**Description:** {self.FRAMEWORK_PILLARS['pillar_4']['description']}

**What Exceptional Looks Like:**
{json.dumps(self.FRAMEWORK_PILLARS['pillar_4']['what_exceptional_looks_like'], indent=2)}

**What is NOT Sufficient:**
{json.dumps(self.FRAMEWORK_PILLARS['pillar_4']['what_NOT_sufficient'], indent=2)}

**Strong Signals to Look For:**
{json.dumps(self.FRAMEWORK_PILLARS['pillar_4']['strong_signals'], indent=2)}

Score: 0-10 (same scale as above)

### Pillar 5: {self.FRAMEWORK_PILLARS['pillar_5']['name']} (Weight: {self.FRAMEWORK_PILLARS['pillar_5']['weight']}%)

**Description:** {self.FRAMEWORK_PILLARS['pillar_5']['description']}

**What Exceptional Looks Like:**
{json.dumps(self.FRAMEWORK_PILLARS['pillar_5']['what_exceptional_looks_like'], indent=2)}

**What is NOT Sufficient:**
{json.dumps(self.FRAMEWORK_PILLARS['pillar_5']['what_NOT_sufficient'], indent=2)}

**Strong Signals to Look For:**
{json.dumps(self.FRAMEWORK_PILLARS['pillar_5']['strong_signals'], indent=2)}

Score: 0-10 (same scale as above)

### Pillar 6: {self.FRAMEWORK_PILLARS['pillar_6']['name']} (Weight: {self.FRAMEWORK_PILLARS['pillar_6']['weight']}%)

**Description:** {self.FRAMEWORK_PILLARS['pillar_6']['description']}

**What Exceptional Looks Like:**
{json.dumps(self.FRAMEWORK_PILLARS['pillar_6']['what_exceptional_looks_like'], indent=2)}

**What is NOT Sufficient:**
{json.dumps(self.FRAMEWORK_PILLARS['pillar_6']['what_NOT_sufficient'], indent=2)}

**Strong Signals to Look For:**
{json.dumps(self.FRAMEWORK_PILLARS['pillar_6']['strong_signals'], indent=2)}

Score: 0-10 (same scale as above)

## STEP 6: Must-Have Signals Check (ALL Required for Strong Screen)

Does candidate demonstrate ALL of these?
{json.dumps(self.MUST_HAVE_SIGNALS, indent=2)}

Missing any ‚Üí max decision = "Screen" (not "Strong Screen")

## STEP 7: Differentiation Signals Check (Need 3+ for Strong Screen)

Count how many of these the candidate demonstrates:
{json.dumps(self.DIFFERENTIATION_SIGNALS, indent=2)}

- 0-2 differentiators ‚Üí "Maybe" or "Screen"
- 3-5 differentiators ‚Üí "Screen" or "Strong Screen"
- 6+ differentiators ‚Üí Likely "Strong Screen"

## STEP 8: Final Decision Criteria

**Calculate Total Score:**
- Sum of all 6 pillar scores = Total Score (out of 60)

**Decision Thresholds:**
- **Strong Screen (48-60 points)**: Meets all must-haves + 3+ differentiators + no red flags + Pillar 3 ‚â• 7
- **Screen (36-47 points)**: Meets most must-haves + some differentiators + 1-2 yellow flags acceptable
- **Maybe (24-35 points)**: Missing some must-haves or multiple yellow flags + requires further conversation
- **No Screen (<24 points)**: Fails minimum thresholds or has red flags or Pillar 3 < 6

# OUTPUT FORMAT

Return your analysis as JSON with this EXACT structure:

{{
  "candidate_name": "Name from resume",
  "analysis_date": "{datetime.now().isoformat()}",
  "minimum_thresholds_met": {{
    "personal_ai_projects": true/false,
    "building_in_public": true/false,
    "resume_creativity": true/false,
    "all_met": true/false
  }},
  "red_flags_found": ["list any red flags found, or empty array"],
  "yellow_flags_found": ["list any yellow flags found, or empty array"],
  "critical_questions_analysis": {{
    "paradigm_shift_examples": ["specific projects showing transformational vs incremental thinking"],
    "future_proofing_examples": ["projects architected for future AI capabilities"],
    "magic_wand_examples": ["projects designed for eventual full automation"]
  }},
  "pillars": {{
    "pillar_1": {{
      "name": "{self.FRAMEWORK_PILLARS['pillar_1']['name']}",
      "score": 0-10,
      "level": "Developing|Functional|Proficient|Advanced|Expert",
      "evidence": "Specific examples from resume with quotes",
      "strengths": ["strength 1", "strength 2", "..."],
      "gaps": ["gap 1", "gap 2", "..."]
    }},
    "pillar_2": {{
      "name": "{self.FRAMEWORK_PILLARS['pillar_2']['name']}",
      "score": 0-10,
      "level": "Developing|Functional|Proficient|Advanced|Expert",
      "evidence": "Specific examples from resume with quotes",
      "strengths": ["strength 1", "strength 2", "..."],
      "gaps": ["gap 1", "gap 2", "..."]
    }},
    "pillar_3": {{
      "name": "{self.FRAMEWORK_PILLARS['pillar_3']['name']}",
      "score": 0-10,
      "level": "Developing|Functional|Proficient|Advanced|Expert",
      "evidence": "Specific examples from resume with quotes",
      "strengths": ["strength 1", "strength 2", "..."],
      "gaps": ["gap 1", "gap 2", "..."]
    }},
    "pillar_4": {{
      "name": "{self.FRAMEWORK_PILLARS['pillar_4']['name']}",
      "score": 0-10,
      "level": "Developing|Functional|Proficient|Advanced|Expert",
      "evidence": "Specific examples from resume with quotes",
      "strengths": ["strength 1", "strength 2", "..."],
      "gaps": ["gap 1", "gap 2", "..."]
    }},
    "pillar_5": {{
      "name": "{self.FRAMEWORK_PILLARS['pillar_5']['name']}",
      "score": 0-10,
      "level": "Developing|Functional|Proficient|Advanced|Expert",
      "evidence": "Specific examples from resume with quotes",
      "strengths": ["strength 1", "strength 2", "..."],
      "gaps": ["gap 1", "gap 2", "..."]
    }},
    "pillar_6": {{
      "name": "{self.FRAMEWORK_PILLARS['pillar_6']['name']}",
      "score": 0-10,
      "level": "Developing|Functional|Proficient|Advanced|Expert",
      "evidence": "Specific examples from resume with quotes",
      "strengths": ["strength 1", "strength 2", "..."],
      "gaps": ["gap 1", "gap 2", "..."]
    }}
  }},
  "must_have_signals": {{
    "signals_found": ["which must-have signals were found"],
    "signals_missing": ["which must-have signals were missing"],
    "all_present": true/false
  }},
  "differentiation_signals": {{
    "signals_found": ["which differentiation signals were found"],
    "count": number,
    "sufficient_for_strong_screen": true/false
  }},
  "total_score": 0-60,
  "decision": "Strong Screen|Screen|Maybe|No Screen",
  "decision_rationale": "2-3 sentences explaining the decision based on framework",
  "top_strengths": ["strength 1", "strength 2", "strength 3"],
  "top_concerns": ["concern 1", "concern 2", "concern 3"],
  "recommendation": "Detailed 3-5 sentence recommendation",
  "suitable_roles": ["specific role suggestions based on profile"],
  "interview_focus_areas": ["areas to probe deeper in interview"]
}}

# IMPORTANT INSTRUCTIONS

1. **Be CRITICAL and RIGOROUS** - This is 2025, the bar is high
2. **Look for EVIDENCE** - Claims without examples = not sufficient
3. **Speed matters** - Building in hours/days, not weeks/months
4. **Personal projects trump corporate work** - We want builders who can't NOT build
5. **AI depth is NON-NEGOTIABLE** - Pillar 3 score < 6 = automatic No Screen
6. **Creative range matters** - Portfolio approach (8-10 concurrent projects) is exceptional
7. **Quote SPECIFIC examples** from the resume in your evidence
8. **Apply The Three Critical Questions** to judge quality of thinking
9. **Check for building in public** - Blog/LinkedIn/GitHub/speaking presence

Return ONLY valid JSON, nothing else."""
        return prompt

    def analyze_with_ai(self, resume_text, resume_image=None):
        """Send resume to AI for analysis (with optional visual analysis)"""
        import base64
        from io import BytesIO

        prompt = self.create_analysis_prompt(resume_text)

        try:
            if self.api_provider == "openai":
                # Prepare messages
                messages = [
                    {"role": "system", "content": "You are an expert AI PM hiring consultant. Return valid JSON only."}
                ]

                # If image available, add vision analysis
                if resume_image:
                    # Convert PIL image to base64
                    buffered = BytesIO()
                    resume_image.save(buffered, format="PNG")
                    img_str = base64.b64encode(buffered.getvalue()).decode()

                    messages.append({
                        "role": "user",
                        "content": [
                            {
                                "type": "text",
                                "text": prompt + "\n\nADDITIONALLY: Evaluate the VISUAL DESIGN of this resume. Consider: creativity, visual hierarchy, readability, professional appearance, use of color/typography, and whether design demonstrates product taste. Include this in your analysis under a 'design_evaluation' field with score (0-10) and comments."
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/png;base64,{img_str}"
                                }
                            }
                        ]
                    })
                else:
                    messages.append({"role": "user", "content": prompt})

                params = {
                    "model": self.model,
                    "messages": messages,
                    "response_format": {"type": "json_object"}
                }

                # Only add temperature for non-GPT-5 models
                if not self.model.startswith("gpt-5"):
                    params["temperature"] = 0.3

                response = self.client.chat.completions.create(**params)
                result = response.choices[0].message.content

            elif self.api_provider == "anthropic":
                # Prepare content blocks
                content_blocks = []

                # Add image if available
                if resume_image:
                    buffered = BytesIO()
                    resume_image.save(buffered, format="PNG")
                    img_str = base64.b64encode(buffered.getvalue()).decode()

                    content_blocks.append({
                        "type": "image",
                        "source": {
                            "type": "base64",
                            "media_type": "image/png",
                            "data": img_str
                        }
                    })
                    content_blocks.append({
                        "type": "text",
                        "text": prompt + "\n\nADDITIONALLY: Evaluate the VISUAL DESIGN of this resume shown in the image. Consider: creativity, visual hierarchy, readability, professional appearance, use of color/typography, and whether design demonstrates product taste. Include this in your analysis under a 'design_evaluation' field with score (0-10) and comments."
                    })
                else:
                    content_blocks.append({
                        "type": "text",
                        "text": prompt
                    })

                response = self.client.messages.create(
                    model=self.model,
                    max_tokens=4000,
                    temperature=0.3,
                    messages=[
                        {"role": "user", "content": content_blocks}
                    ]
                )
                result = response.content[0].text

                # Claude may wrap JSON in markdown code blocks, extract it
                if "```json" in result:
                    result = result.split("```json")[1].split("```")[0].strip()
                elif "```" in result:
                    result = result.split("```")[1].split("```")[0].strip()

            elif self.api_provider == "google":
                # Prepare content parts
                content_parts = []

                if resume_image:
                    # Gemini can accept PIL images directly
                    content_parts.append(resume_image)
                    content_parts.append(prompt + "\n\nADDITIONALLY: Evaluate the VISUAL DESIGN of this resume shown in the image. Consider: creativity, visual hierarchy, readability, professional appearance, use of color/typography, and whether design demonstrates product taste. Include this in your analysis under a 'design_evaluation' field with score (0-10) and comments.")
                else:
                    content_parts.append(prompt)

                response = self.client.generate_content(
                    content_parts,
                    generation_config=genai.GenerationConfig(
                        temperature=0.3,
                        response_mime_type="application/json"
                    )
                )
                result = response.text

            # Parse JSON response
            analysis = json.loads(result)
            return analysis

        except Exception as e:
            raise Exception(f"AI analysis failed: {str(e)}")

    def analyze_resume(self, file_path):
        """Main analysis function"""
        file_ext = Path(file_path).suffix.lower()
        file_type = {'.pdf': 'PDF', '.doc': 'DOC', '.docx': 'DOCX'}.get(file_ext, 'document')
        print(f"üìÑ Extracting text from {file_type}...")
        resume_text = self.extract_text_from_document(file_path)

        # Try to get visual representation for PDF files
        resume_image = None
        if file_ext == '.pdf':
            print(f"üñºÔ∏è  Converting PDF to image for visual design analysis...")
            resume_image = self.convert_pdf_to_images(file_path)
            if resume_image:
                print(f"‚úÖ Visual analysis enabled")
            else:
                print(f"‚ö†Ô∏è  Visual analysis unavailable (install pdf2image for design evaluation)")

        print(f"ü§ñ Analyzing with {self.api_provider.upper()} ({self.model})...")
        analysis = self.analyze_with_ai(resume_text, resume_image)

        # Add metadata about the analysis
        analysis['_metadata'] = {
            'provider': self.api_provider,
            'model': self.model,
            'model_display_name': self.AVAILABLE_MODELS[self.api_provider][self.model]['name'],
            'visual_analysis': resume_image is not None
        }

        print(f"‚úÖ Analysis complete!")
        return analysis


def check_env_file():
    """Check if .env file exists and has required keys"""
    env_path = Path.cwd() / '.env'

    if not env_path.exists():
        print("‚ö†Ô∏è  No .env file found!")
        print("\nCreating .env template...")

        env_template = """# AI PM Resume Analyzer - API Keys Configuration
# Add your API keys below (you only need ONE of these)

# OpenAI API Key (GPT-5)
# Get yours at: https://platform.openai.com/api-keys
# Default: GPT-5 | Optional: gpt-5-mini, gpt-4o
OPENAI_API_KEY=

# Anthropic API Key (Claude Sonnet 4.5)
# Get yours at: https://console.anthropic.com/settings/keys
# Default: Claude Sonnet 4.5 | Optional: claude-haiku-4-5, claude-opus-4-1
ANTHROPIC_API_KEY=

# Google API Key (Gemini 2.5 Pro)
# Get yours at: https://aistudio.google.com/app/apikey
# Default: Gemini 2.5 Pro | Optional: gemini-2.5-flash
GOOGLE_API_KEY=

# Default provider (openai, anthropic, or google)
DEFAULT_PROVIDER=openai
"""

        with open(env_path, 'w') as f:
            f.write(env_template)

        print(f"‚úÖ Created .env file at: {env_path}")
        print("\nüìù SETUP INSTRUCTIONS:")
        print("\n1. Get an API key from ONE of these providers:")
        print("   ‚Ä¢ OpenAI (GPT-4): https://platform.openai.com/api-keys")
        print("   ‚Ä¢ Anthropic (Claude): https://console.anthropic.com/settings/keys")
        print("   ‚Ä¢ Google (Gemini): https://aistudio.google.com/app/apikey")
        print("\n2. Open the .env file and paste your API key")
        print("3. Save the file and run the analyzer again")
        print("\nFor detailed setup help, see README.md")
        sys.exit(0)

    # Load environment variables
    load_dotenv(env_path)

    # Check which keys are available
    openai_key = os.getenv('OPENAI_API_KEY')
    anthropic_key = os.getenv('ANTHROPIC_API_KEY')
    google_key = os.getenv('GOOGLE_API_KEY')

    available_providers = []
    if openai_key:
        available_providers.append('openai')
    if anthropic_key:
        available_providers.append('anthropic')
    if google_key:
        available_providers.append('google')

    if not available_providers:
        print("‚ùå No API keys found in .env file!")
        print("\nPlease add at least one API key to your .env file:")
        print("   ‚Ä¢ OPENAI_API_KEY=your_key_here")
        print("   ‚Ä¢ ANTHROPIC_API_KEY=your_key_here")
        print("   ‚Ä¢ GOOGLE_API_KEY=your_key_here")
        print("\nSee README.md for detailed instructions.")
        sys.exit(1)

    return available_providers


def main():
    parser = argparse.ArgumentParser(
        description='AI PM Resume Analyzer - Evaluate resumes against the 6-pillar framework',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Analyze with default provider (from .env)
  ./bin/analyze resume.pdf

  # Specify provider
  ./bin/analyze resume.pdf --provider anthropic
  ./bin/analyze resume.pdf --provider google

  # Custom output location
  ./bin/analyze resume.pdf --output ./reports/

For setup help, see README.md
        """
    )

    parser.add_argument('resume', nargs='?', help='Path to resume file (.pdf, .doc, .docx)')
    parser.add_argument('--provider', choices=['openai', 'anthropic', 'google'],
                        help='AI provider to use (overrides .env DEFAULT_PROVIDER)')
    parser.add_argument('--model',
                        help='Specific model to use (e.g., gpt-5, gpt-5-mini, claude-haiku-4-5, gemini-2.5-flash)')
    parser.add_argument('--output', default='./output',
                        help='Output directory for analysis reports (default: ./output)')
    parser.add_argument('--format', choices=['markdown', 'html', 'both'], default='both',
                        help='Output format (default: both)')
    parser.add_argument('--list-models', action='store_true',
                        help='List all available models and exit')
    parser.add_argument('--deep-analysis', action='store_true',
                        help='Run analysis with ALL available providers and aggregate results for maximum feedback')

    args = parser.parse_args()

    # Handle --list-models flag
    if args.list_models:
        print("\nüìã Available Models by Provider:\n")
        for provider, models in ResumeAnalyzer.AVAILABLE_MODELS.items():
            print(f"üîπ {provider.upper()}:")
            for model_id, info in models.items():
                default_marker = " (default)" if model_id == ResumeAnalyzer.DEFAULT_MODELS[provider] else ""
                print(f"  ‚Ä¢ {model_id:<35} - {info['name']:<25} {info['cost']:<5} - {info['description']}{default_marker}")
            print()
        print("Usage: ./analyze resume.pdf --provider <provider> --model <model_id>\n")
        sys.exit(0)

    # Validate resume argument is provided
    if not args.resume:
        parser.error("resume path is required (or use --list-models to see available models)")

    # Check environment setup
    print("üîç Checking API configuration...")
    available_providers = check_env_file()
    load_dotenv()

    # Determine which provider to use
    provider = args.provider or os.getenv('DEFAULT_PROVIDER', 'openai')

    if provider not in available_providers:
        print(f"‚ùå Provider '{provider}' selected but no API key found!")
        print(f"\n‚úÖ Available providers: {', '.join(available_providers)}")
        print(f"\nEither:")
        print(f"  1. Add {provider.upper()}_API_KEY to your .env file")
        print(f"  2. Use a different provider: --provider {available_providers[0]}")
        sys.exit(1)

    # Get API key
    api_key = os.getenv(f'{provider.upper()}_API_KEY')

    # Check if resume file exists
    if not os.path.exists(args.resume):
        print(f"‚ùå Resume file not found: {args.resume}")
        sys.exit(1)

    # Validate file extension
    resume_ext = Path(args.resume).suffix.lower()
    if resume_ext not in ['.pdf', '.doc', '.docx']:
        print(f"‚ùå Unsupported file format: {resume_ext}")
        print(f"   Supported formats: .pdf, .doc, .docx")
        sys.exit(1)

    # Create output directory
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    # Handle deep analysis mode
    if args.deep_analysis:
        print("\nüî¨ DEEP ANALYSIS MODE")
        print("=" * 60)
        print("Running analysis with all available providers...")
        print(f"Available providers: {', '.join(available_providers)}")
        print("=" * 60 + "\n")

        analyses = {}
        for prov in available_providers:
            try:
                prov_key = os.getenv(f'{prov.upper()}_API_KEY')
                print(f"ü§ñ Analyzing with {prov.upper()}...")

                # Use default (best) model for each provider
                prov_analyzer = ResumeAnalyzer(api_provider=prov, api_key=prov_key, model=None)
                prov_analysis = prov_analyzer.analyze_resume(args.resume)
                analyses[prov] = prov_analysis

                print(f"‚úÖ {prov.upper()} complete: {prov_analysis.get('total_score', 0)}/60")
            except Exception as e:
                print(f"‚ö†Ô∏è  {prov.upper()} failed: {str(e)}")

        if not analyses:
            print("‚ùå No analyses completed successfully")
            sys.exit(1)

        # Generate aggregated reports
        from templates.output_generator import generate_aggregated_report, generate_aggregated_html

        candidate_name = list(analyses.values())[0].get('candidate_name', 'Candidate').replace(' ', '_')
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        base_filename = f"{candidate_name}_DEEP_{timestamp}"

        # Generate consolidated markdown report
        md_path = output_dir / f"{base_filename}.md"
        generate_aggregated_report(analyses, md_path)
        print(f"\nüìù Aggregated Markdown Report: {md_path}")

        # Generate consolidated HTML report
        html_path = output_dir / f"{base_filename}.html"
        generate_aggregated_html(analyses, html_path)
        print(f"üåê Aggregated HTML Report: {html_path}")

        # Save individual JSONs (for reference/debugging)
        for prov, analysis in analyses.items():
            json_path = output_dir / f"{base_filename}_{prov}.json"
            with open(json_path, 'w') as f:
                json.dump(analysis, f, indent=2)
        print(f"üíæ Individual JSON files saved (3 files)")

        print(f"\n‚ú® Deep analysis complete! Analyzed with {len(analyses)} provider(s)")
        sys.exit(0)

    try:
        # Initialize analyzer
        analyzer = ResumeAnalyzer(api_provider=provider, api_key=api_key, model=args.model)

        # Run analysis
        analysis = analyzer.analyze_resume(args.resume)

        # Generate output files
        from templates.output_generator import generate_markdown, generate_html

        candidate_name = analysis.get('candidate_name', 'Candidate').replace(' ', '_')
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        base_filename = f"{candidate_name}_{timestamp}"

        if args.format in ['markdown', 'both']:
            md_path = output_dir / f"{base_filename}.md"
            generate_markdown(analysis, md_path)
            print(f"üìù Markdown report: {md_path}")

        if args.format in ['html', 'both']:
            html_path = output_dir / f"{base_filename}.html"
            generate_html(analysis, html_path)
            print(f"üåê HTML report: {html_path}")

        # Also save JSON
        json_path = output_dir / f"{base_filename}.json"
        with open(json_path, 'w') as f:
            json.dump(analysis, f, indent=2)
        print(f"üíæ JSON data: {json_path}")

        print(f"\n‚ú® Analysis complete! Total score: {analysis.get('total_score', 0)}/60")
        print(f"üìä Decision: {analysis.get('decision', 'Unknown')}")

    except Exception as e:
        print(f"\n‚ùå Error: {str(e)}")
        sys.exit(1)


if __name__ == '__main__':
    main()
